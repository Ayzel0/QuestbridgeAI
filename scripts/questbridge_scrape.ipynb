{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLEGE_UL = [\n",
    "    '(//ul[@class=\"subsubCategoryItems\"])[5]',\n",
    "    '(//ul[@class=\"subsubCategoryItems\"])[6]',\n",
    "    '(//ul[@class=\"subsubCategoryItems\"])[7]',\n",
    "    '(//ul[@class=\"subsubCategoryItems\"])[8]'\n",
    "]\n",
    "APP_REQS = '//a[text()=\"Application Requirements\"]'\n",
    "FINAID = '//a[text()=\"Financial Aid\"]'\n",
    "ACADEMICS = '//a[text()=\"Academics\"]'\n",
    "ACADEMIC_HIGHLIGHTS = '//section[@class=\"lcol col-sm-12 col-md-7\"]'\n",
    "\n",
    "class QBScraper:\n",
    "    def __init__(self, url):\n",
    "        self.driver = None\n",
    "        self.url = url\n",
    "    \n",
    "    def create_driver(self):\n",
    "        self.driver = webdriver.Chrome()\n",
    "        self.driver.get(self.url)\n",
    "        self.driver.maximize_window()\n",
    "        self.wait = WebDriverWait(self.driver, 10)\n",
    "\n",
    "    def scrape_colleges(self):\n",
    "        college_json = {}\n",
    "        for ul_xpath in COLLEGE_UL:\n",
    "            college_ul = self.wait.until(EC.presence_of_element_located((By.XPATH, ul_xpath)))\n",
    "            college_li_items = college_ul.find_elements(By.TAG_NAME, 'li')\n",
    "\n",
    "            # get links\n",
    "            links = []\n",
    "            for item in college_li_items:\n",
    "                # get link\n",
    "                link = item.find_element(By.TAG_NAME, 'a')\n",
    "                href = link.get_attribute('href')\n",
    "                links.append(href)\n",
    "            \n",
    "            for link in links:\n",
    "                self.driver.get(link)\n",
    "\n",
    "                college_name = self.wait.until(EC.presence_of_element_located((By.TAG_NAME, 'h1'))).get_attribute('innerText')\n",
    "\n",
    "                # navigate to app reqs\n",
    "                application_reqs_tab = self.wait.until(EC.presence_of_element_located((By.XPATH, APP_REQS)))\n",
    "                application_reqs_tab.click()\n",
    "\n",
    "                # check if page is blank\n",
    "                college_info = {}\n",
    "                if len(self.driver.find_elements(By.TAG_NAME, 'table')) != 0:\n",
    "                    # scrape application requirements\n",
    "                    app_reqs_dict = self.find_application_requirements()\n",
    "\n",
    "                    # navigate to match reqs\n",
    "                    post_match_dict = self.find_post_match_options()\n",
    "\n",
    "                    application_requirements = {\n",
    "                        'Match Requirements': app_reqs_dict,\n",
    "                        'Post-Match Options': post_match_dict\n",
    "                    }\n",
    "                    college_info['Application Info'] = application_requirements\n",
    "\n",
    "                # navigate to aid tab\n",
    "                finaid_tab = self.wait.until(EC.presence_of_element_located((By.XPATH, FINAID)))\n",
    "                finaid_tab.click()\n",
    "\n",
    "                # check if page is blank\n",
    "                if len(self.driver.find_elements(By.TAG_NAME, 'table')) != 0:\n",
    "                    # scrape aid data\n",
    "                    college_info['Financial Aid Data'] = self.scrape_aid_data()\n",
    "                \n",
    "                # navigate to academics tab\n",
    "                academics_tab = self.wait.until(EC.presence_of_element_located((By.XPATH, ACADEMICS)))\n",
    "                academics_tab.click()\n",
    "\n",
    "                # scrape academic highlights\n",
    "                academic_highlights = self.scrape_academic_highlights()\n",
    "                college_info['Academic Highlights'] = academic_highlights\n",
    "                college_json[college_name] = college_info\n",
    "        with open ('questbridge_data.json', 'w') as file:\n",
    "            json.dump(college_json, file, indent=4)\n",
    "    \n",
    "    def find_application_requirements(self):\n",
    "        app_reqs_dict = {}\n",
    "\n",
    "        # navigate to match reqs table\n",
    "        match_reqs_table = self.wait.until(EC.presence_of_element_located((By.TAG_NAME, 'table')))\n",
    "        rows = match_reqs_table.find_elements(By.TAG_NAME, 'tr')\n",
    "        \n",
    "        # get the match requirements deadline\n",
    "        row_header = rows[0].find_element(By.TAG_NAME, 'th').get_attribute('innerText')\n",
    "        deadline = row_header.split('\\n')[-1].strip().split(':')[-1].strip()\n",
    "        app_reqs_dict['Deadline'] = deadline\n",
    "\n",
    "        # iterate over the rest of the rows\n",
    "        for row in rows[1:]:\n",
    "            # check if we're at the three-column row\n",
    "            if row.find_element(By.TAG_NAME, 'td').get_attribute('colspan') != '3':\n",
    "                # TODO: swap above to == 3 so that we can portal activation data\n",
    "\n",
    "                # check if we're looking at rows with codes, since we want the codes\n",
    "                second_col = row.find_elements(By.TAG_NAME, 'td')[1]\n",
    "                if (len(second_col.find_elements(By.TAG_NAME, 'p')) > 1):\n",
    "                    codes = second_col.find_elements(By.TAG_NAME, 'p')[1].get_attribute('innerText')\n",
    "                    for code in codes.split('\\n'):\n",
    "                        code = code.strip()\n",
    "                        if 'ACT' in code:\n",
    "                            code = ''.join(re.findall(r'\\d+', code))\n",
    "                            app_reqs_dict['ACT Code'] = code\n",
    "                        elif 'SAT' in code:\n",
    "                            code = ''.join(re.findall(r'\\d+', code))\n",
    "                            app_reqs_dict['SAT Code'] = code\n",
    "                        elif 'CSS' in code:\n",
    "                            code = ''.join(re.findall(r'\\d+', code))\n",
    "                            app_reqs_dict['CSS Code'] = code\n",
    "                        elif 'FAFSA' in code:\n",
    "                            code = ''.join(re.findall(r'\\d+', code))\n",
    "                            app_reqs_dict['FAFSA Code'] = code\n",
    "\n",
    "                    key = second_col.find_element(By.TAG_NAME, 'p').get_attribute('innerText').replace('\\xa0', ' ').replace('\\n', ' ').strip()\n",
    "                    value = row.find_elements(By.TAG_NAME, 'td')[2].get_attribute('innerText').replace('\\xa0', ' ').replace('\\n', ' ').strip()\n",
    "                    app_reqs_dict[key] = value\n",
    "                \n",
    "                # else if we're not looking at a row with codes? just grab the second col as the key and the third col as the value for the kv pair in dict\n",
    "                else:\n",
    "                    key = second_col.get_attribute('innerText').replace('\\xa0', ' ').replace('\\n', ' ').strip()\n",
    "                    value = row.find_elements(By.TAG_NAME, 'td')[2].get_attribute('innerText').replace('\\xa0', ' ').replace('\\n', ' ').strip()\n",
    "                    app_reqs_dict[key] = value\n",
    "        return app_reqs_dict\n",
    "\n",
    "    def find_post_match_options(self):\n",
    "        post_match_dict = {}\n",
    "\n",
    "        table = self.driver.find_elements(By.TAG_NAME, 'table')[1]\n",
    "        rows = table.find_elements(By.TAG_NAME, 'tr')\n",
    "        for row in rows[1:]:\n",
    "            key = row.find_element(By.TAG_NAME, 'p').get_attribute('innerText')\n",
    "            value = row.find_elements(By.TAG_NAME, 'td')[1].get_attribute('innerText')\n",
    "            post_match_dict[key] = value\n",
    "        \n",
    "        return post_match_dict\n",
    "    \n",
    "    def scrape_aid_data(self):\n",
    "        aid_dict = {}\n",
    "        cost_dict = {}\n",
    "        cover_dict = {}\n",
    "\n",
    "        cost_table = self.wait.until(EC.presence_of_element_located((By.TAG_NAME, 'table')))\n",
    "        rows = cost_table.find_elements(By.TAG_NAME, 'tr')\n",
    "        for row in rows[1:]:\n",
    "            key = row.find_element(By.TAG_NAME, 'p').get_attribute('innerText')\n",
    "            value = row.find_elements(By.TAG_NAME, 'td')[1].get_attribute('innerText')\n",
    "            cost_dict[key] = value\n",
    "        \n",
    "        aid_table = self.driver.find_elements(By.TAG_NAME, 'table')[1]\n",
    "        rows = aid_table.find_elements(By.TAG_NAME, 'tr')\n",
    "        for row in rows[1:]:\n",
    "            key = row.find_element(By.TAG_NAME, 'p').get_attribute('innerText')\n",
    "            value = row.find_elements(By.TAG_NAME, 'td')[1].get_attribute('innerText')\n",
    "            cover_dict[key] = value\n",
    "        \n",
    "        aid_dict['Costs of Attendance'] = cost_dict\n",
    "        aid_dict['How Costs are Covered'] = cover_dict\n",
    "        return aid_dict\n",
    "    \n",
    "    def scrape_academic_highlights(self):\n",
    "        academic_highlights_arr = []\n",
    "        ul = self.wait.until(EC.presence_of_element_located((By.XPATH, ACADEMIC_HIGHLIGHTS))).find_element(By.TAG_NAME, 'ul')\n",
    "        list_items = ul.find_elements(By.TAG_NAME, 'li')\n",
    "        for item in list_items:\n",
    "            value = item.find_element(By.TAG_NAME, 'p').get_attribute('innerText').replace('\\xa0', ' ')\n",
    "            academic_highlights_arr.append(value)\n",
    "        return academic_highlights_arr        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"tag name\",\"selector\":\"p\"}\n  (Session info: chrome=120.0.6099.225); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF754902142+3514994]\n\t(No symbol) [0x00007FF754520CE2]\n\t(No symbol) [0x00007FF7543C76AA]\n\t(No symbol) [0x00007FF754411860]\n\t(No symbol) [0x00007FF75441197C]\n\t(No symbol) [0x00007FF7544064FC]\n\t(No symbol) [0x00007FF75443602F]\n\t(No symbol) [0x00007FF7544063B6]\n\t(No symbol) [0x00007FF754436490]\n\t(No symbol) [0x00007FF7544528F6]\n\t(No symbol) [0x00007FF754435D93]\n\t(No symbol) [0x00007FF754404BDC]\n\t(No symbol) [0x00007FF754405C64]\n\tGetHandleVerifier [0x00007FF75492E16B+3695259]\n\tGetHandleVerifier [0x00007FF754986737+4057191]\n\tGetHandleVerifier [0x00007FF75497E4E3+4023827]\n\tGetHandleVerifier [0x00007FF7546504F9+689705]\n\t(No symbol) [0x00007FF75452C048]\n\t(No symbol) [0x00007FF754528044]\n\t(No symbol) [0x00007FF7545281C9]\n\t(No symbol) [0x00007FF7545188C4]\n\tBaseThreadInitThunk [0x00007FF955A0257D+29]\n\tRtlUserThreadStart [0x00007FF95684AA58+40]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m scraper \u001b[38;5;241m=\u001b[39m QBScraper(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.questbridge.org/college-partners\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m scraper\u001b[38;5;241m.\u001b[39mcreate_driver()\n\u001b[1;32m----> 3\u001b[0m \u001b[43mscraper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscrape_colleges\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 50\u001b[0m, in \u001b[0;36mQBScraper.scrape_colleges\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     47\u001b[0m college_info \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mTAG_NAME, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# scrape application requirements\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m     app_reqs_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_application_requirements\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;66;03m# navigate to match reqs\u001b[39;00m\n\u001b[0;32m     53\u001b[0m     post_match_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfind_post_match_options()\n",
      "Cell \u001b[1;32mIn[4], line 125\u001b[0m, in \u001b[0;36mQBScraper.find_application_requirements\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[38;5;66;03m# else if we're not looking at a row with codes? just grab the second col as the key and the third col as the value for the kv pair in dict\u001b[39;00m\n\u001b[0;32m    123\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m             key \u001b[38;5;241m=\u001b[39m second_col\u001b[38;5;241m.\u001b[39mget_attribute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minnerText\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\xa0\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m--> 125\u001b[0m             value \u001b[38;5;241m=\u001b[39m \u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_elements\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTAG_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtd\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTAG_NAME\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget_attribute(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minnerText\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\xa0\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m    126\u001b[0m             app_reqs_dict[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m app_reqs_dict\n",
      "File \u001b[1;32mc:\\Users\\Andrew\\.conda\\envs\\datascience\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:416\u001b[0m, in \u001b[0;36mWebElement.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    413\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    414\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 416\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_CHILD_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Andrew\\.conda\\envs\\datascience\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:394\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    392\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    393\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[1;32m--> 394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Andrew\\.conda\\envs\\datascience\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:344\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    342\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 344\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    345\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\Andrew\\.conda\\envs\\datascience\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"tag name\",\"selector\":\"p\"}\n  (Session info: chrome=120.0.6099.225); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF754902142+3514994]\n\t(No symbol) [0x00007FF754520CE2]\n\t(No symbol) [0x00007FF7543C76AA]\n\t(No symbol) [0x00007FF754411860]\n\t(No symbol) [0x00007FF75441197C]\n\t(No symbol) [0x00007FF7544064FC]\n\t(No symbol) [0x00007FF75443602F]\n\t(No symbol) [0x00007FF7544063B6]\n\t(No symbol) [0x00007FF754436490]\n\t(No symbol) [0x00007FF7544528F6]\n\t(No symbol) [0x00007FF754435D93]\n\t(No symbol) [0x00007FF754404BDC]\n\t(No symbol) [0x00007FF754405C64]\n\tGetHandleVerifier [0x00007FF75492E16B+3695259]\n\tGetHandleVerifier [0x00007FF754986737+4057191]\n\tGetHandleVerifier [0x00007FF75497E4E3+4023827]\n\tGetHandleVerifier [0x00007FF7546504F9+689705]\n\t(No symbol) [0x00007FF75452C048]\n\t(No symbol) [0x00007FF754528044]\n\t(No symbol) [0x00007FF7545281C9]\n\t(No symbol) [0x00007FF7545188C4]\n\tBaseThreadInitThunk [0x00007FF955A0257D+29]\n\tRtlUserThreadStart [0x00007FF95684AA58+40]\n"
     ]
    }
   ],
   "source": [
    "scraper = QBScraper('https://www.questbridge.org/college-partners')\n",
    "scraper.create_driver()\n",
    "scraper.scrape_colleges()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
