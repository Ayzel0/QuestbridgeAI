{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLEGE_UL = '(//ul[@class=\"subsubCategoryItems\"])[6]'\n",
    "APP_REQS = '//a[text()=\"Application Requirements\"]'\n",
    "FINAID = '//a[text()=\"Financial Aid\"]'\n",
    "ACADEMICS = '//a[text()=\"Academics\"]'\n",
    "ACADEMIC_HIGHLIGHTS = '//section[@class=\"lcol col-sm-12 col-md-7\"]'\n",
    "\n",
    "class QBScraper:\n",
    "    def __init__(self, url):\n",
    "        self.driver = None\n",
    "        self.url = url\n",
    "    \n",
    "    def create_driver(self):\n",
    "        self.driver = webdriver.Chrome()\n",
    "        self.driver.get(self.url)\n",
    "        self.driver.maximize_window()\n",
    "        self.wait = WebDriverWait(self.driver, 10)\n",
    "\n",
    "    def scrape_colleges(self):\n",
    "        college_ul = self.wait.until(EC.presence_of_element_located((By.XPATH, COLLEGE_UL)))\n",
    "        college_li_items = college_ul.find_elements(By.TAG_NAME, 'li')\n",
    "\n",
    "        # get links\n",
    "        links = []\n",
    "        for item in college_li_items:\n",
    "            # get link\n",
    "            link = item.find_element(By.TAG_NAME, 'a')\n",
    "            href = link.get_attribute('href')\n",
    "            links.append(href)\n",
    "        \n",
    "        print(links)\n",
    "        \n",
    "        college_json = {}\n",
    "        for link in links:\n",
    "            self.driver.get(link)\n",
    "\n",
    "            college_name = self.wait.until(EC.presence_of_element_located((By.TAG_NAME, 'h1'))).get_attribute('innerText')\n",
    "\n",
    "            # navigate to app reqs\n",
    "            application_reqs_tab = self.wait.until(EC.presence_of_element_located((By.XPATH, APP_REQS)))\n",
    "            application_reqs_tab.click()\n",
    "\n",
    "            # check if page is blank\n",
    "            college_info = {}\n",
    "            if len(self.driver.find_elements(By.TAG_NAME, 'table')) != 0:\n",
    "                # scrape application requirements\n",
    "                app_reqs_dict = self.find_application_requirements()\n",
    "\n",
    "                # navigate to match reqs\n",
    "                post_match_dict = self.find_post_match_options()\n",
    "\n",
    "                application_requirements = {\n",
    "                    'Match Requirements': app_reqs_dict,\n",
    "                    'Post-Match Options': post_match_dict\n",
    "                }\n",
    "                college_info['Application Info'] = application_requirements\n",
    "\n",
    "            # navigate to aid tab\n",
    "            finaid_tab = self.wait.until(EC.presence_of_element_located((By.XPATH, FINAID)))\n",
    "            finaid_tab.click()\n",
    "\n",
    "            # check if page is blank\n",
    "            if len(self.driver.find_elements(By.TAG_NAME, 'table')) != 0:\n",
    "                # scrape aid data\n",
    "                college_info['Financial Aid Data'] = self.scrape_aid_data()\n",
    "            \n",
    "            # navigate to academics tab\n",
    "            academics_tab = self.wait.until(EC.presence_of_element_located((By.XPATH, ACADEMICS)))\n",
    "            academics_tab.click()\n",
    "\n",
    "            # scrape academic highlights\n",
    "            academic_highlights = self.scrape_academic_highlights()\n",
    "            college_info['Academic Highlights'] = academic_highlights\n",
    "            college_json[college_name] = college_info\n",
    "        with open ('questbridge_data.json', 'w') as file:\n",
    "            json.dump(college_json, file, indent=4)\n",
    "    \n",
    "    def find_application_requirements(self):\n",
    "        app_reqs_dict = {}\n",
    "\n",
    "        # navigate to match reqs table\n",
    "        match_reqs_table = self.wait.until(EC.presence_of_element_located((By.TAG_NAME, 'table')))\n",
    "        rows = match_reqs_table.find_elements(By.TAG_NAME, 'tr')\n",
    "        \n",
    "        # get the match requirements deadline\n",
    "        row_header = rows[0].find_element(By.TAG_NAME, 'th').get_attribute('innerText')\n",
    "        deadline = row_header.split('\\n')[-1].strip().split(':')[-1].strip()\n",
    "        app_reqs_dict['Deadline'] = deadline\n",
    "\n",
    "        # iterate over the rest of the rows\n",
    "        for row in rows[1:]:\n",
    "            # check if we're at the three-column row\n",
    "            if row.find_element(By.TAG_NAME, 'td').get_attribute('colspan') != '3':\n",
    "                # TODO: swap above to == 3 so that we can portal activation data\n",
    "\n",
    "                # check if we're looking at rows with codes, since we want the codes\n",
    "                second_col = row.find_elements(By.TAG_NAME, 'td')[1]\n",
    "                if (len(second_col.find_elements(By.TAG_NAME, 'p')) > 1):\n",
    "                    codes = second_col.find_elements(By.TAG_NAME, 'p')[1].get_attribute('innerText')\n",
    "                    for code in codes.split('\\n'):\n",
    "                        code = code.strip()\n",
    "                        if 'ACT' in code:\n",
    "                            code = ''.join(re.findall(r'\\d+', code))\n",
    "                            app_reqs_dict['ACT Code'] = code\n",
    "                        elif 'SAT' in code:\n",
    "                            code = ''.join(re.findall(r'\\d+', code))\n",
    "                            app_reqs_dict['SAT Code'] = code\n",
    "                        elif 'CSS' in code:\n",
    "                            code = ''.join(re.findall(r'\\d+', code))\n",
    "                            app_reqs_dict['CSS Code'] = code\n",
    "                        elif 'FAFSA' in code:\n",
    "                            code = ''.join(re.findall(r'\\d+', code))\n",
    "                            app_reqs_dict['FAFSA Code'] = code\n",
    "\n",
    "                    key = second_col.find_element(By.TAG_NAME, 'p').get_attribute('innerText').replace('\\xa0', ' ').replace('\\n', ' ').strip()\n",
    "                    value = row.find_elements(By.TAG_NAME, 'td')[2].find_element(By.TAG_NAME, 'p').get_attribute('innerText').replace('\\xa0', ' ').replace('\\n', ' ').strip()\n",
    "                    app_reqs_dict[key] = value\n",
    "                \n",
    "                # else if we're not looking at a row with codes? just grab the second col as the key and the third col as the value for the kv pair in dict\n",
    "                else:\n",
    "                    key = second_col.get_attribute('innerText').replace('\\xa0', ' ').replace('\\n', ' ').strip()\n",
    "                    value = row.find_elements(By.TAG_NAME, 'td')[2].find_element(By.TAG_NAME, 'p').get_attribute('innerText').replace('\\xa0', ' ').replace('\\n', ' ').strip()\n",
    "                    app_reqs_dict[key] = value\n",
    "        return app_reqs_dict\n",
    "\n",
    "    def find_post_match_options(self):\n",
    "        post_match_dict = {}\n",
    "\n",
    "        table = self.driver.find_elements(By.TAG_NAME, 'table')[1]\n",
    "        rows = table.find_elements(By.TAG_NAME, 'tr')\n",
    "        for row in rows[1:]:\n",
    "            key = row.find_element(By.TAG_NAME, 'p').get_attribute('innerText')\n",
    "            value = row.find_elements(By.TAG_NAME, 'td')[1].find_element(By.TAG_NAME, 'p').get_attribute('innerText')\n",
    "            post_match_dict[key] = value\n",
    "        \n",
    "        return post_match_dict\n",
    "    \n",
    "    def scrape_aid_data(self):\n",
    "        aid_dict = {}\n",
    "        cost_dict = {}\n",
    "        cover_dict = {}\n",
    "\n",
    "        cost_table = self.wait.until(EC.presence_of_element_located((By.TAG_NAME, 'table')))\n",
    "        rows = cost_table.find_elements(By.TAG_NAME, 'tr')\n",
    "        for row in rows[1:]:\n",
    "            key = row.find_element(By.TAG_NAME, 'p').get_attribute('innerText')\n",
    "            value = row.find_elements(By.TAG_NAME, 'td')[1].get_attribute('innerText')\n",
    "            cost_dict[key] = value\n",
    "        \n",
    "        aid_table = self.driver.find_elements(By.TAG_NAME, 'table')[1]\n",
    "        rows = aid_table.find_elements(By.TAG_NAME, 'tr')\n",
    "        for row in rows[1:]:\n",
    "            key = row.find_element(By.TAG_NAME, 'p').get_attribute('innerText')\n",
    "            value = row.find_elements(By.TAG_NAME, 'td')[1].get_attribute('innerText')\n",
    "            cover_dict[key] = value\n",
    "        \n",
    "        aid_dict['Costs of Attendance'] = cost_dict\n",
    "        aid_dict['How Costs are Covered'] = cover_dict\n",
    "        return aid_dict\n",
    "    \n",
    "    def scrape_academic_highlights(self):\n",
    "        academic_highlights_arr = []\n",
    "        ul = self.wait.until(EC.presence_of_element_located((By.XPATH, ACADEMIC_HIGHLIGHTS))).find_element(By.TAG_NAME, 'ul')\n",
    "        list_items = ul.find_elements(By.TAG_NAME, 'li')\n",
    "        for item in list_items:\n",
    "            value = item.find_element(By.TAG_NAME, 'p').get_attribute('innerText').replace('\\xa0', ' ')\n",
    "            academic_highlights_arr.append(value)\n",
    "        return academic_highlights_arr        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.questbridge.org/college-partners/colorado-college', 'https://www.questbridge.org/college-partners/columbia-university', 'https://www.questbridge.org/college-partners/cornell-university', 'https://www.questbridge.org/college-partners/dartmouth-college', 'https://www.questbridge.org/college-partners/davidson-college', 'https://www.questbridge.org/college-partners/denison-university', 'https://www.questbridge.org/college-partners/duke-university', 'https://www.questbridge.org/college-partners/emory-university', 'https://www.questbridge.org/college-partners/grinnell-college', 'https://www.questbridge.org/college-partners/hamilton-college', 'https://www.questbridge.org/college-partners/haverford-college', 'https://www.questbridge.org/college-partners/johns-hopkins-university', 'https://www.questbridge.org/college-partners/macalester-college']\n"
     ]
    }
   ],
   "source": [
    "scraper = QBScraper('https://www.questbridge.org/college-partners')\n",
    "scraper.create_driver()\n",
    "scraper.scrape_colleges()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
